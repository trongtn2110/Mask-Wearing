{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_fasterRCNN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBS6MGrWPwvc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFS6CwQQVIOx"
      },
      "source": [
        "#**TIẾN HÀNH DOWNLOAD DATA VỀ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMQKmVYD0mjX"
      },
      "source": [
        "# Mount drive CỦA CÁ NHÂN\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5G7F5W4r3ty"
      },
      "source": [
        "import gdown\n",
        "%cd /content/gdrive/My\\ Drive\n",
        "!mkdir Data_CS114\n",
        "%cd /content/gdrive/My\\ Drive/Data_CS114"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2eIhVgar5Yg"
      },
      "source": [
        "!gdown --id 1FRg4q4qTi2ImfpMxE5EnLeDRCHNxo13C #Testimg.zip\n",
        "!gdown --id 1gDtyugP41svdzTfWaWyysWC4Co3X0rIs #Testlabel.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFIEWiXUiOAL"
      },
      "source": [
        "!mkdir Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF5DReLX1JeI"
      },
      "source": [
        "#UNZIP data\n",
        "!unzip testimg.zip -d \"/content/gdrive/MyDrive/Data_CS114/Test\"\n",
        "\n",
        "!unzip testlabel.zip -d \"/content/gdrive/MyDrive/Data_CS114/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4l2n9bU04Um"
      },
      "source": [
        "# import các thư viện cần thiết\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os \n",
        "from PIL import Image\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "import requests\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.patches as patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thyoxVlHszY7"
      },
      "source": [
        "# path of images directory\n",
        "img_test_path = '/content/gdrive/MyDrive/Data_CS114/Test/testimg'\n",
        "\n",
        "# path of xml files directory\n",
        "label_test_path = '/content/gdrive/MyDrive/Data_CS114/Test/test_label'\n",
        "\n",
        "# List of Image file name \n",
        "\n",
        "img_test_list = list(sorted(os.listdir(img_test_path)))\n",
        "label_test_list= list(sorted(os.listdir(label_test_path)))\n",
        "\n",
        "# How many image files?\n",
        "#print('There are total {} images train and {} images test.'.format(len(img_train_list),len(img_test_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXP-D9auWFwi"
      },
      "source": [
        "#**HÀM ĐỌC LABEL VÀ VẼ BOUNDING BOX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ80nsKW2lyF"
      },
      "source": [
        "# Helper function for read the data (label and bounding boxes) from xml file \n",
        "def read_label(file_name, label_dir):\n",
        "    \"\"\"\n",
        "    Function used to get the bounding boxes and labels from the xml file\n",
        "    Input:\n",
        "        file_name: image file name\n",
        "        xml_dir: directory of xml file\n",
        "    Return:\n",
        "        bbox : list of bounding boxes\n",
        "        labels: list of labels\n",
        "    \"\"\"\n",
        "    bbox = []\n",
        "    labels = []\n",
        "    \n",
        "    label_path = os.path.join(label_dir, file_name[:-3]+'xml')\n",
        "    tree = ET.parse(label_path)\n",
        "    root = tree.getroot()\n",
        "    for boxes in root.iter('object'):\n",
        "        ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
        "        xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
        "        ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
        "        xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
        "        label = boxes.find('name').text\n",
        "        bbox.append([xmin,ymin,xmax,ymax])\n",
        "        if label == 'Correct':\n",
        "            label_idx = 1\n",
        "        elif label == 'No-mask':\n",
        "          label_idx = 2\n",
        "        elif label == 'Incorrect':\n",
        "            label_idx = 3\n",
        "        labels.append(label_idx)\n",
        "        \n",
        "    return bbox, labels\n",
        "\n",
        "# help function for drawing bounding boxes on image\n",
        "def draw_boxes(img, boxes,labels, thickness=3):\n",
        "    \"\"\"\n",
        "    Function to draw bounding boxes\n",
        "    Input:\n",
        "        img: array of img (h, w ,c)\n",
        "        boxes: list of boxes (int)\n",
        "        labels: list of labels (int)\n",
        "    \n",
        "    \"\"\"\n",
        "    font =  cv2.FONT_HERSHEY_SIMPLEX\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    for box,label in zip(boxes,labels):\n",
        "        box = [int(x) for x in box]\n",
        "        if label == 3:\n",
        "          color = (255,0,255) #pink\n",
        "          text = 'Incorrect'\n",
        "        elif label == 2:\n",
        "          color = (0,0,225) # red\n",
        "          text = 'Nomask'\n",
        "        elif label == 1:\n",
        "          color = (0,255,0) # green\n",
        "          text = 'Correct'\n",
        "        cv2.putText(img,text,(box[0],box[1]), font, 1 ,color, thickness)\n",
        "        cv2.rectangle(img, (box[0],box[1]),(box[2],box[3]),color,thickness)\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpjTPSehWJR-"
      },
      "source": [
        "#**THIẾT LẬP DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mArP8UAz3amt"
      },
      "source": [
        "class image_dataset(Dataset):\n",
        "    def __init__(self, image_list, image_dir, label_train_dir):\n",
        "        self.image_list = image_list\n",
        "        self.image_dir = image_dir\n",
        "        self.xml_dir = label_train_dir\n",
        "        self.classes = [_, 'Correct','No-mask','Incorrect']\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Load the image\n",
        "        \"\"\"\n",
        "        img_name = self.image_list[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = transforms.ToTensor()(img)\n",
        "\n",
        "        \"\"\"\n",
        "        build the target dict\n",
        "        \"\"\"\n",
        "        bbox, labels = read_label(img_name, self.xml_dir)\n",
        "        boxes = torch.as_tensor(bbox, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        \n",
        "        area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n",
        "        area = torch.as_tensor(area, dtype=torch.float32)\n",
        "        iscrowd = torch.zeros((len(bbox),), dtype=torch.int64)\n",
        "        \n",
        "        target = {}\n",
        "        \n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = labels\n",
        "        target['image_id'] = torch.tensor([idx])\n",
        "        target['area'] = area\n",
        "        target['iscrowed'] = iscrowd\n",
        "        return img , target\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return len(self.image_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDGHz5VV4E5d"
      },
      "source": [
        "\n",
        "mask_dataset_test = image_dataset(img_test_list, img_test_path, label_test_path)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "mask_loader_test = DataLoader(mask_dataset_test,batch_size=10,shuffle=True,num_workers=4,collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIALBpWCWMyn"
      },
      "source": [
        "#**THIẾT LẬP CÁC THAM SỐ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbEohBgV4QIu"
      },
      "source": [
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4X9DvV1wCXT"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0i8ZTfF4kit"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/Data_CS114\n",
        "!gdown --id 1UaAA1bB3xkwzqtbSK639R0xbeD5bXAeh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9c3OAv4quN"
      },
      "source": [
        "model = get_model_instance_segmentation(4)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/Data_CS114/model_final_cs114_1.pth'))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC6UfPozwM7w"
      },
      "source": [
        "#**PREDICT MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw7dQP3g4wv8"
      },
      "source": [
        "def single_img_predict(img, nm_thrs = 0.3, score_thrs=0.5):\n",
        "    test_img = transforms.ToTensor()(img)\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        predictions = model(test_img.unsqueeze(0).to(device))\n",
        "        \n",
        "    test_img = test_img.permute(1,2,0).numpy()\n",
        "    \n",
        "    # non-max supression\n",
        "    keep_boxes = torchvision.ops.nms(predictions[0]['boxes'].cpu(),predictions[0]['scores'].cpu(),nm_thrs)\n",
        "    \n",
        "    # Only display the bounding boxes which higher than the threshold\n",
        "    score_filter =  predictions[0]['scores'].cpu().numpy()[keep_boxes] > score_thrs\n",
        "    # get the filtered result\n",
        "    test_boxes = predictions[0]['boxes'].cpu().numpy()[keep_boxes][score_filter]\n",
        "    test_labels = predictions[0]['labels'].cpu().numpy()[keep_boxes][score_filter]\n",
        "    \n",
        "    return test_img, test_boxes, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cekyckLLwd8C"
      },
      "source": [
        "    idx = random.randint(1,len(img_test_list))\n",
        "    # idx = 210\n",
        "    test_img = Image.open(os.path.join(img_test_path,img_test_list[idx]))\n",
        "    # test_img = test_img.cuda()\n",
        "    # Prediction\n",
        "    test_img, test_boxes, test_labels= single_img_predict(test_img)\n",
        "    # print(test_boxes)\n",
        "    # print(test_labels)\n",
        "    # print(score[:len(test_labels)])\n",
        "    test_output = draw_boxes(test_img, test_boxes,test_labels)\n",
        "    # t = test_output\n",
        "\n",
        "    # Draw the bounding box of ground truth\n",
        "    bbox, labels  = read_label(img_test_list[idx], label_test_path)\n",
        "    # #draw bounding boxes on the image\n",
        "    gt_output = draw_boxes(test_img, bbox,labels)\n",
        "    print(idx)\n",
        "    # img1 = Image.fromarray((test_output * 150).astype(np.uint8))\n",
        "    # img1 = img1.convert('RGB')\n",
        "    # img1.save(\"/content/drive/MyDrive/Data_Project_CS114/Predict/imagePred{}.jpg\".format(idx))\n",
        "    # Display the result\n",
        "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(40,80))\n",
        "    ax1.imshow(test_output)\n",
        "    ax1.set_xlabel('Prediction')\n",
        "    ax2.imshow(gt_output)\n",
        "    ax2.set_xlabel('Ground Truth')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}